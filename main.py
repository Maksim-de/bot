import requests
from datetime import datetime, timedelta
import pytz
import bs4
import psycopg2
import logging
import time

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[logging.StreamHandler()]
)
logger = logging.getLogger(__name__)


category_keywords = {
 "–ê–Ω–∞–ª–∏—Ç–∏–∫–∞": {
    "keywords": [
      "–∞–Ω–∞–ª–∏—Ç–∏–∫", 'systems_analyst', 'data_analyst', 'business_analyst', 'bi-–∞–Ω–∞–ª–∏—Ç–∏–∫', '–±–∏–∑–Ω–µ—Å-–∞–Ω–∞–ª–∏—Ç–∏–∫', 'marketing_analyst',
      'bi_developer', 'bi-–∞–Ω–∞–ª–∏—Ç–∏–∫, –∞–Ω–∞–ª–∏—Ç–∏–∫ –¥–∞–Ω–Ω—ã—Ö', 'c–∏—Å—Ç–µ–º–Ω—ã–π –∞–Ω–∞–ª–∏—Ç–∏–∫', 'soc_analyst'
    ],
    "subcategories": {
      "–°–∏—Å—Ç–µ–º–Ω—ã–π –∞–Ω–∞–ª–∏—Ç–∏–∫": [
        "—Å–∏—Å—Ç–µ–º–Ω", "systems_analyst",  "uml", 'c–∏—Å—Ç–µ–º–Ω—ã–π –∞–Ω–∞–ª–∏—Ç–∏–∫', '—Å–∏—Å—Ç–µ–º–Ω—ã–π', 'systems'
      ],
      "–ë–∏–∑–Ω–µ—Å –∞–Ω–∞–ª–∏—Ç–∏–∫": [
        "–±–∏–∑–Ω–µ—Å", "business", '–±–∏–∑–Ω–µ—Å-–∞–Ω–∞–ª–∏—Ç–∏–∫', 'business_analyst'
      ],
      "Data –∞–Ω–∞–ª–∏—Ç–∏–∫ –∏ BI": [
        'data_analyst', 'bi-–∞–Ω–∞–ª–∏—Ç–∏–∫', "bi_developer", 'bi-–∞–Ω–∞–ª–∏—Ç–∏–∫, –∞–Ω–∞–ª–∏—Ç–∏–∫ –¥–∞–Ω–Ω—ã—Ö'
      ],
      "–ü—Ä–æ–¥—É–∫—Ç–æ–≤—ã–π –∞–Ω–∞–ª–∏—Ç–∏–∫": [
        "–ø—Ä–æ–¥—É–∫—Ç–æ–≤", "product", "a/b", "ab test", "a/b test", '–ø—Ä–æ–¥—É–∫—Ç–æ–≤—ã–π –∞–Ω–∞–ª–∏—Ç–∏–∫'
      ],
      "–ê–Ω–∞–ª–∏—Ç–∏–∫ DWH": [
        "data engineer", "dwh", "data warehouse", "airflow", "data lake",
        "databricks", "spark", "hadoop", 'sql'
      ],
      "–í–µ–±-–∞–Ω–∞–ª–∏—Ç–∏–∫": [
        "–≤–µ–±", "web",
      ],
      "–ê–Ω–∞–ª–∏—Ç–∏–∫ (–¥—Ä—É–≥–æ–µ)": []
  }
},
 "–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ": {
    "keywords": [
      "—Ç–µ—Å—Ç–∏—Ä–æ–≤—â–∏–∫", "tester", "qa", "quality assurance", "—Ç–µ—Å—Ç–∏—Ä–æ–≤—â–∏–∫-–∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ç–æ—Ä",
      "qa engineer", "–∏–Ω–∂–µ–Ω–µ—Ä –ø–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω", "—Ä—É—á–Ω —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω", "–∞–≤—Ç–æ–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω",
      "–º–æ–±–∏–ª—å–Ω —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω", "–≤–µ–± —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω", "–≥–µ–π–º —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω", "api —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω",
      "–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω", "–ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω", "–Ω–∞–≥—Ä—É–∑–æ—á–Ω —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω",
      "–∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–æ–Ω —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω", "—Ä–µ–≥—Ä–µ—Å—Å–∏–æ–Ω —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω", "smoke —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω", "–ø—Ä–∏–µ–º–æ—á–Ω —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω",
      "quality manager", "qa lead", "qa architect", 'manual_testing', 'test_automation', 'qa_engineer'
    ],
    "subcategories": {
      "–†—É—á–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ": [
        "—Ä—É—á–Ω —Ç–µ—Å—Ç–∏—Ä–æ–≤—â–∏–∫", '—Ä—É—á–Ω–æ–µ', '—Ä—É—á–Ω–æ–≥–æ', 'manual_testing'
      ],
      "–ê–≤—Ç–æ–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ": [
        "–∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ç–æ—Ä —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω", "automation tester", "qa automation", "test_automation"
      ],
     "–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ (–î—Ä—É–≥–æ–µ)": []
    }
},
 "–†–∞–∑—Ä–∞–±–æ—Ç–∫–∞": {
    "keywords": [
      "frontend", "front-end", "front end", "javascript", "js",
      "react", "angular", "vue", "typescript", 'software',
      "backend", 'devops', 'mobileapp_developer', "data_engineer", 'database_developer',
      "fullstack", "full-stack", "full stack", "devops-–∏–Ω–∂–µ–Ω–µ—Ä", 'database_architect', 'database_admin', '–±–∞–∑ –¥–∞–Ω–Ω—ã—Ö', '—Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∞'
    ],
    "subcategories": {
      "Frontend —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∞": [
        "frontend", "front-end", "front end", "javascript", "js",
        "react", "angular", "vue", "typescript", "ui developer"
      ],
      "Backend —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∞": [
        "backend", "back-end", "back end", "server", "api",
        "python", "java", "php", "node", "nodejs", "net", "ruby", "go", "golang"
      ],
      "Fullstack —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∞": [
        "fullstack", "full-stack", "full stack",
      ],
      "–ú–æ–±–∏–ª—å–Ω–∞—è —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∞": [
        "mobile", "android", "ios", "flutter", "react",
        "–∫–æ—Ç–ª–∏–Ω", "kotlin", "swift", "mobileapp_developer", '–º–æ–±–∏–ª—å–Ω–∞—è'
      ],
      "DevOps": [
        "devops", "DevOps-–∏–Ω–∂–µ–Ω–µ—Ä"
      ],
      "Data engineer": [
        "data_engineer", 'database_developer', 'database_architect', 'database_admin', '–±–∞–∑ –¥–∞–Ω–Ω—ã—Ö'
      ],
  "–†–∞–∑—Ä–∞–±–æ—Ç–∫–∞ (–î—Ä—É–≥–æ–µ)": []
    }
},
 "ML/AI/DS": {
    "keywords": [
      "ml engineer", "ml-engineer", "mlops", 'data_scientist', 'ml', 'ai', '–ø—Ä–æ–º—Ç', '–¥–∞—Ç–∞-—Å–∞–π–µ–Ω—Ç–∏—Å—Ç'
    ],
    "subcategories": {
      "Data Science": [
        "data science", "–∞–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω", "–¥–∞—Ç–∞-—Å–∞–π–µ–Ω—Ç–∏—Å—Ç", "data_scientist", '–¥–∞—Ç–∞-—Å–∞–π–µ–Ω—Ç–∏—Å—Ç'
      ],
      "ML Engineering": [
        "ml engineer", "ml-engineer", "mlops", "model serving"
      ],
       "AI (–î—Ä—É–≥–æ–µ)": []
    }
},
 "–ú–µ–Ω–µ–¥–∂–º–µ–Ω—Ç": {
    "keywords": [
      '–º–µ–Ω–µ–¥–∂–µ—Ä –ø—Ä–æ–¥—É–∫—Ç–∞', '—Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—å –≥—Ä—É–ø–ø—ã —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏', '—Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—å –æ—Ç–¥–µ–ª–∞ –∞–Ω–∞–ª–∏—Ç–∏–∫–∏', "—Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—å –ø—Ä–æ–µ–∫—Ç–æ–≤", 'project_manager',
      'project_director', 'product_manager', 'marketing_manager', 'account_manager', 'cio', '—Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π –¥–∏—Ä–µ–∫—Ç–æ—Ä (—Å—Ç–æ)', 'cto'
    ],

    "subcategories": {
      "–ü—Ä–æ–¥—É–∫—Ç–æ–≤—ã–π –º–µ–Ω–µ–¥–∂–º–µ–Ω—Ç": [
        "–ø—Ä–æ–¥—É–∫—Ç–æ–≤ –º–µ–Ω–µ–¥–∂–µ—Ä", "product manager", "PM", "product owner",
        "—Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—å –ø—Ä–æ–¥—É–∫—Ç", "head of product", 'product_manager'
      ],
      "–ü—Ä–æ–µ–∫—Ç–Ω—ã–π –º–µ–Ω–µ–¥–∂–º–µ–Ω—Ç": [
        "–ø—Ä–æ–µ–∫—Ç–Ω –º–µ–Ω–µ–¥–∂–µ—Ä", "project manager", "PM", "—Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—å –ø—Ä–æ–µ–∫—Ç–æ–≤", 'project_manager', 'scrum_master', 'account_manager'
      ],
      "–ò–¢ —Ç–æ–ø –º–µ–Ω–µ–¥–∂–º–µ–Ω—Ç": [
        '—Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—å –≥—Ä—É–ø–ø—ã —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏',  '—Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—å –æ—Ç–¥–µ–ª–∞ –∞–Ω–∞–ª–∏—Ç–∏–∫–∏', '—Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π –¥–∏—Ä–µ–∫—Ç–æ—Ä (—Å—Ç–æ)',  'project_director', 'cio', '—Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π', 'cto'
      ],

"–ú–µ–Ω–µ–¥–∂–µ—Ä (–î—Ä—É–≥–æ–µ)": []
 }
    }
}

category_keywords_work = {

    "–ê–Ω–∞–ª–∏—Ç–∏–∫–∞": {
        "keywords": ["–∞–Ω–∞–ª–∏—Ç–∏–∫", "–±–∏–∑–Ω–µ—Å –∞–Ω–∞–ª–∏—Ç–∏–∫" "analyst", "–∞–Ω–∞–ª–∏—Ç–∏–∫ –¥–∞–Ω–Ω—ã—Ö", "data analyst", "–±–∏–∑–Ω–µ—Å-–∞–Ω–∞–ª–∏—Ç–∏–∫", "business analyst", "BI-–∞–Ω–∞–ª–∏—Ç–∏–∫", "BI analyst", "—Å–∏—Å—Ç–µ–º–Ω—ã–π –∞–Ω–∞–ª–∏—Ç–∏–∫", "system analyst", "–≤–µ–±-–∞–Ω–∞–ª–∏—Ç–∏–∫", "web analyst"],
        "subcategories": {
            "–°–∏—Å—Ç–µ–º–Ω—ã–π –∞–Ω–∞–ª–∏—Ç–∏–∫": ["—Å–∏—Å—Ç–µ–º–Ω—ã–π", "system analyst", 'c–∏—Å—Ç–µ–º–Ω—ã–π –∞–Ω–∞–ª–∏—Ç–∏–∫', 'systems', 'systems analyst', 'ystem'],
            "–ë–∏–∑–Ω–µ—Å-–∞–Ω–∞–ª–∏—Ç–∏–∫": ["–±–∏–∑–Ω–µ—Å-–∞–Ω–∞–ª–∏—Ç–∏–∫", "business analyst", "–∞–Ω–∞–ª–∏—Ç–∏–∫ –ø—Ä–æ—Ü–µ—Å—Å–æ–≤", "process analyst", "full stack", "–±–∏–∑–Ω–µ—Å"],
            "Data –∞–Ω–∞–ª–∏—Ç–∏–∫ & BI": ["–∞–Ω–∞–ª–∏—Ç–∏–∫ –¥–∞–Ω–Ω—ã—Ö", "data", "–¥–∞–Ω–Ω—ã—Ö", "bi", "–∞–Ω–∞–ª–∏—Ç–∏–∫ –æ—Ç—á–µ—Ç–Ω–æ—Å—Ç–∏", "data analytics specialist"],
            "–ü—Ä–æ–¥—É–∫—Ç–æ–≤—ã–π –∞–Ω–∞–ª–∏—Ç–∏–∫": ["–ø—Ä–æ–¥—É–∫—Ç–æ–≤—ã–π –∞–Ω–∞–ª–∏—Ç–∏–∫", "product analyst", "–ø—Ä–æ–¥—É–∫—Ç–æ–≤—ã–π"],
            "–í–µ–±-–∞–Ω–∞–ª–∏—Ç–∏–∫": ["–≤–µ–±-–∞–Ω–∞–ª–∏—Ç–∏–∫", "web analyst", "google analytics analyst", "–∞–Ω–∞–ª–∏—Ç–∏–∫ –º–µ—Ç—Ä–∏–∫", "–∞–Ω–∞–ª–∏—Ç–∏–∫ —Ç—Ä–∞—Ñ–∏–∫–∞"],
            "–ê–Ω–∞–ª–∏—Ç–∏–∫ DWH": ["data engineer", "dwh", "data warehouse", "airflow", "data lake", "databricks", "spark", "hadoop", 'sql'],
            "–î—Ä—É–≥–æ–µ": []
}
    },
    "–†–∞–∑—Ä–∞–±–æ—Ç–∫–∞": {
        "keywords": ["—Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫", "developer", "–ø—Ä–æ–≥—Ä–∞–º–º–∏—Å—Ç", "engineer", "dev", "software", "–ø—Ä–∏–ª–æ–∂–µ–Ω–∏–π", "application", "–∫–æ–¥", "code"],
        "subcategories": {
            "Frontend —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∞": ["frontend", "front-end", "front end", "javascript", "js", "react", "angular", "vue", "typescript", "ui developer"],
            "Backend —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∞": ["backend", "back-end", "back end", "server", "api", "python", "java", "php", "node", "nodejs", "net", ".net", "go", "golang"],
            "Fullstack —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∞": ["fullstack", "full-stack", "full stack", "—É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫","full", "mean", "lamp"],
            "–ú–æ–±–∏–ª—å–Ω–∞—è —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∞": ["mobile", "android", "ios", "flutter", "react", "–∫–æ—Ç–ª–∏–Ω", "kotlin", "swift", "mobileapp_developer"],
            "DevOps": ["devops", "DevOps-–∏–Ω–∂–µ–Ω–µ—Ä"],
            "–†–∞–∑—Ä–∞–±–æ—Ç–∫–∞ (–î—Ä—É–≥–æ–µ)": []
}
},
     "–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ": {
        "keywords": ["—Ç–µ—Å—Ç–∏—Ä–æ–≤—â–∏–∫", "tester", "qa", "quality assurance", "manual_testing", "—Ç–µ—Å—Ç", "test", "qa engineer", "–∏–Ω–∂–µ–Ω–µ—Ä –ø–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—é"],
        "subcategories": {
            "–†—É—á–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ": ["—Ä—É—á–Ω–æ–π —Ç–µ—Å—Ç–∏—Ä–æ–≤—â–∏–∫", "manual tester", "qa manual", "—Ç–µ—Å—Ç–∏—Ä–æ–≤—â–∏–∫ —Ä—É—á–Ω–æ–≥–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è", "manual qa engineer", 'manual_testing'],
            "–ê–≤—Ç–æ–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ": ['test_automation', 'qa', "–∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ç–æ—Ä —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è", "automation tester", "qa automation", "–∏–Ω–∂–µ–Ω–µ—Ä –ø–æ –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏–∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è", "automation qa engineer"],
            "–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ (–î—Ä—É–≥–æ–µ)": []
}
},
     "ML/AI/DS": {
        "keywords": ["ml", "ai", 'ds', "data science", "–¥–∞—Ç–∞-—Å–∞–π–µ–Ω—Ç–∏—Å—Ç"],
         "subcategories": {
            "Data Science": ["data science", "–∞–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω", "–¥–∞—Ç–∞-—Å–∞–π–µ–Ω—Ç–∏—Å—Ç", "data_scientist", '–¥–∞—Ç–∞-—Å–∞–π–µ–Ω—Ç–∏—Å—Ç', 'ds'],
            "ML Engineering": ["engineer", "ml-engineer", "mlops", "model serving"],
       "AI (–î—Ä—É–≥–æ–µ)": []
}
},
 "–ú–µ–Ω–µ–¥–∂–º–µ–Ω—Ç": {
    "keywords": [
      '–º–µ–Ω–µ–¥–∂–µ—Ä –ø—Ä–æ–¥—É–∫—Ç–∞', '–º–µ–Ω–µ–¥–∂–µ—Ä' '—Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—å –≥—Ä—É–ø–ø—ã —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏', '—Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—å –æ—Ç–¥–µ–ª–∞ –∞–Ω–∞–ª–∏—Ç–∏–∫–∏', "—Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—å –ø—Ä–æ–µ–∫—Ç–æ–≤", 'project_manager',
      'project_director', 'product_manager', 'marketing_manager', 'account_manager', 'cio', '—Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π –¥–∏—Ä–µ–∫—Ç–æ—Ä (—Å—Ç–æ)', 'cto'
    ],

    "subcategories": {
      "–ü—Ä–æ–¥—É–∫—Ç–æ–≤—ã–π –º–µ–Ω–µ–¥–∂–º–µ–Ω—Ç": [
        "–ø—Ä–æ–¥—É–∫—Ç–æ–≤ –º–µ–Ω–µ–¥–∂–µ—Ä", "product manager", "PM", "product owner",
        "—Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—å –ø—Ä–æ–¥—É–∫—Ç", "head of product", 'product_manager', '–ø—Ä–æ–¥—É–∫—Ç','–º–µ–Ω–µ–¥–∂–µ—Ä –ø—Ä–æ–¥—É–∫—Ç–∞'
      ],
      "–ü—Ä–æ–µ–∫—Ç–Ω—ã–π –º–µ–Ω–µ–¥–∂–º–µ–Ω—Ç": [
        "–ø—Ä–æ–µ–∫—Ç–Ω –º–µ–Ω–µ–¥–∂–µ—Ä", "project manager", "PM", "—Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—å –ø—Ä–æ–µ–∫—Ç–æ–≤", 'project_manager', 'scrum_master', 'account_manager'
      ],
      "–ò–¢ —Ç–æ–ø –º–µ–Ω–µ–¥–∂–º–µ–Ω—Ç": [
        '—Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—å –≥—Ä—É–ø–ø—ã —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏',  '—Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—å –æ—Ç–¥–µ–ª–∞ –∞–Ω–∞–ª–∏—Ç–∏–∫–∏', '—Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π –¥–∏—Ä–µ–∫—Ç–æ—Ä (—Å—Ç–æ)',  'project_director', 'cio', '—Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π', 'cto'
      ],

"–ú–µ–Ω–µ–¥–∂–µ—Ä (–î—Ä—É–≥–æ–µ)": []
 }
    }
}


# –ü–∞—Ä—Å–∏–º —Å hh –∏ —Ö–∞–±—Ä–∞ –∏ –≥—Ä—É–∑–∏–º –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö

import requests
from datetime import datetime, timedelta
import pytz
from bs4 import BeautifulSoup
import json
import re



def hh_parsing():
    today = datetime.now().date()
    yesterday = today - timedelta(days=1)
    date_from = yesterday.strftime("%Y-%m-%dT00:00:00")
    date_to = today.strftime("%Y-%m-%dT23:59:59")

    # –†–∞–∑–±–∏–≤–∞–µ–º —Ä–æ–ª–∏ –Ω–∞ 3 –ª–æ–≥–∏—á–µ—Å–∫–∏–µ –≥—Ä—É–ø–ø—ã –¥–ª—è –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∏ –Ω–∞–≥—Ä—É–∑–∫–∏
    role_groups = [
        ['156', '148', '160', '10',  '150', '165'],  # IT –∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ
        ['36', '73', '96', '164', '104', '157' ],  # –ú–∞—Ä–∫–µ—Ç–∏–Ω–≥ –∏ –ø—Ä–æ–¥–∞–∂–∏
        [  '107', '124', '125'] #,  # –î—Ä—É–≥–∏–µ —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç—ã
        # ['12', '25', '34', '155', '112','113', '114', '116', '121', '126']
    ]
    
    priority_cities = ["–ú–æ—Å–∫–≤–∞", "–°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥", "–ö–∞–∑–∞–Ω—å", "–ù–æ–≤–æ—Å–∏–±–∏—Ä—Å–∫", "–ï–∫–∞—Ç–µ—Ä–∏–Ω–±—É—Ä–≥", '–ö—Ä–∞—Å–Ω–æ—è—Ä—Å–∫', 
                       "–ù–∏–∂–Ω–∏–π –ù–æ–≤–≥–æ—Ä–æ–¥", '–ß–µ–ª—è–±–∏–Ω—Å–∫', '–£—Ñ–∞',
                       "–°–∞–º–∞—Ä–∞", "–†–æ—Å—Ç–æ–≤-–Ω–∞-–î–æ–Ω—É", '–ö—Ä–∞—Å–Ω–æ–¥–∞—Ä', "–û–º—Å–∫", '–í–æ—Ä–æ–Ω–µ–∂', '–ü–µ—Ä–º—å', '–í–æ–ª–≥–æ–≥—Ä–∞–¥']


    all_vacancies = []
    
    for group in role_groups:
        page = 0
        while True:
            params = {
                'professional_role': group,
                'date_from': date_from,
                'date_to': date_to,
                'per_page': 25,
                'page': page
            }
            
            try:
                response = requests.get("https://api.hh.ru/vacancies", params=params)
                response.raise_for_status()
                data = response.json()
                
                if not data['items']:
                    break
                    
                for item in data['items']:
                    if item['area']['name'] in priority_cities:
                      vacancy = {
                          "title": item['name'],
                          "company": item['employer']['name'],
                          "date": item['published_at'],
                          "location": item['area']['name'],
                          "employment": item['employment']['name'],
                          "experience": item['experience']['name'],
                          "salary": item.get('salary'),
                          "skills": item['snippet']['requirement'],
                          "link": item['alternate_url'],
                          'source': 'hh',
                          'vacancy_type': item['professional_roles'][0]['name'],
                          'new_category': classify_vacancy(item['professional_roles'][0]['name'], item['name'])
                      }
                      all_vacancies.append(vacancy)
                
                # print(f"–ì—Ä—É–ø–ø–∞ {group[:3]}..., –°—Ç—Ä–∞–Ω–∏—Ü–∞ {page}: {len(data['items'])} –≤–∞–∫–∞–Ω—Å–∏–π")
                page += 1
                time.sleep(0.5)
                
            except Exception as e:
                print(f"–û—à–∏–±–∫–∞: {str(e)}")
                break
    
    return all_vacancies

def safe_find_text(element, selector, **kwargs):
    found = element.find(selector, **kwargs) if element else None
    return found.text.strip() if found else None


def classify_vacancy(vacancy_type, title):
    a_list = ['–ê–Ω–∞–ª–∏—Ç–∏–∫–∞', '–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ', '–†–∞–∑—Ä–∞–±–æ—Ç–∫–∞', 'ML/AI/DS', '–ú–µ–Ω–µ–¥–∂–º–µ–Ω—Ç']
    vacancy_type = vacancy_type.lower()
    title = title.lower()
    
    # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ –∑–∞–≥–æ–ª–æ–≤–∫—É, –µ—Å–ª–∏ —Ç–∏–ø –≤–∞–∫–∞–Ω—Å–∏–∏ –ø–æ–¥—Ö–æ–¥—è—â–∏–π
    if vacancy_type in ['–∞–Ω–∞–ª–∏—Ç–∏–∫', '–ø—Ä–æ–≥—Ä–∞–º–º–∏—Å—Ç, —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫', '—Ç–µ—Å—Ç–∏—Ä–æ–≤—â–∏–∫', '–∞–Ω–∞–ª–∏—Ç–∏–∫–∞', '—Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∞, –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ']:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –ø–æ –∑–∞–≥–æ–ª–æ–≤–∫—É
        for category in a_list:
            for keyword in category_keywords_work[category]['keywords']:
                if keyword in title:
                    # –¢–µ–ø–µ—Ä—å –ø—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ–¥–∫–∞—Ç–µ–≥–æ—Ä–∏–∏
                    for subcategory in category_keywords_work[category]['subcategories']:
                        for sub_keyword in category_keywords_work[category]['subcategories'][subcategory]:
                            if sub_keyword in title:
                                return f"{category} | {subcategory}"
                    # –ï—Å–ª–∏ –ø–æ–¥–∫–∞—Ç–µ–≥–æ—Ä–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞
                    return f"{category} | {category} (–î—Ä—É–≥–æ–µ)"
    
    # –ï—Å–ª–∏ —Ç–∏–ø –≤–∞–∫–∞–Ω—Å–∏–∏ –Ω–µ –ø–æ–¥–æ—à–µ–ª, –ø—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ vacancy_type
    for category in a_list:
        for keyword in category_keywords[category]['keywords']:
            if keyword in vacancy_type:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ–¥–∫–∞—Ç–µ–≥–æ—Ä–∏–∏
                for subcategory in category_keywords[category]['subcategories']:
                    for sub_keyword in category_keywords[category]['subcategories'][subcategory]:
                        if sub_keyword in vacancy_type:
                            return f"{category} | {subcategory}"
                # –ï—Å–ª–∏ –ø–æ–¥–∫–∞—Ç–µ–≥–æ—Ä–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞
                return f"{category} | {category} (–¥—Ä—É–≥–æ–µ)"
    
    # –ï—Å–ª–∏ –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ
    return "–ù–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–æ | –ù–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–æ"


def get_vacancy_categories(element):
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –≤–∞–∫–∞–Ω—Å–∏–π –∏–∑ —Å—Å—ã–ª–æ–∫ /vacancies/spec/"""
    categories = []
    if element:
        spec_links = element.find_all('a', href=lambda x: x and '/vacancies/spec/' in x)
        for link in spec_links:
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é —á–∞—Å—Ç—å –ø—É—Ç–∏ –∫–∞–∫ –Ω–∞–∑–≤–∞–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
            category = link['href'].split('/')[-1]
            categories.append(category)
    return ', '.join(categories) if categories else ''



def get_vacancy_level(element):
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —É—Ä–æ–≤–µ–Ω—å –≤–∞–∫–∞–Ω—Å–∏–∏ –∏–∑ —Ç–µ–∫—Å—Ç–∞ —Ä—è–¥–æ–º —Å /vacancies?qid"""
    if element:
        level_link = element.find('a', href=lambda x: x and '/vacancies?qid=' in x)
        if level_link:
            return level_link.text.strip()
    return None




def superjob_parsing():
    a_list = []
    pages_to_check = 5

    headers = {
        "X-Api-App-Id": "v3.r.139164433.23ffc5190afedc15a75557bfecf0d17712201794.e87743a3f683bb304e7389b40f1fc40b4a1cbefa"
    }

    # –ö–ª—é—á–∏ –Ω—É–∂–Ω—ã—Ö –ø–æ–¥–∫–∞—Ç–µ–≥–æ—Ä–∏–π: –∞–Ω–∞–ª–∏—Ç–∏–∫–∞, —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∞, —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ, ML/AI/DS, –º–µ–Ω–µ–¥–∂–º–µ–Ω—Ç

    target_keys = {627, 628, 36, 37, 38, 503, 42, 604, 650, 47,48, 50,56, 613, 605, 630, 61}
    priority_cities = ["–ú–æ—Å–∫–≤–∞", "–°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥", "–ö–∞–∑–∞–Ω—å", "–ù–æ–≤–æ—Å–∏–±–∏—Ä—Å–∫", "–ï–∫–∞—Ç–µ—Ä–∏–Ω–±—É—Ä–≥", '–ö—Ä–∞—Å–Ω–æ—è—Ä—Å–∫', 
                       "–ù–∏–∂–Ω–∏–π –ù–æ–≤–≥–æ—Ä–æ–¥", '–ß–µ–ª—è–±–∏–Ω—Å–∫', '–£—Ñ–∞',
                       "–°–∞–º–∞—Ä–∞", "–†–æ—Å—Ç–æ–≤-–Ω–∞-–î–æ–Ω—É", '–ö—Ä–∞—Å–Ω–æ–¥–∞—Ä', "–û–º—Å–∫", '–í–æ—Ä–æ–Ω–µ–∂', '–ü–µ—Ä–º—å', '–í–æ–ª–≥–æ–≥—Ä–∞–¥']

    for page in range(pages_to_check):
        params = {
            "page": page,
            "count": 100,
            "catalogues": 33  # IT-–≤–∞–∫–∞–Ω—Å–∏–∏
        }

        response = requests.get("https://api.superjob.ru/2.0/vacancies/", headers=headers, params=params)

        if response.status_code != 200:
            print("–û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞:", response.status_code)
            continue

        vacancies = response.json().get("objects", [])
        today = datetime.now()  # –¢–µ–ø–µ—Ä—å —ç—Ç–æ datetime, –∞ –Ω–µ date
        
    

        for vac in vacancies:
            
            pub_date = datetime.fromtimestamp(vac.get("date_published", 0))
            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –≤–∞–∫–∞–Ω—Å–∏–∏ —Å—Ç–∞—Ä—à–µ 1 —Å—É—Ç–æ–∫
            if today - pub_date > timedelta(days=1):
                continue

            # üîΩ –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ –ø–æ–¥–∫–∞—Ç–µ–≥–æ—Ä–∏—è–º (positions.key)
            subcatalog_keys = {
                pos.get("key")
                for cat in vac.get("catalogues", [])
                for pos in cat.get("positions", [])
            }
            if not subcatalog_keys & target_keys:
                continue  # –ø—Ä–æ–ø—É—Å–∫–∞–µ–º, –µ—Å–ª–∏ –Ω–∏ –æ–¥–Ω–∞ –ø–æ–¥–∫–∞—Ç–µ–≥–æ—Ä–∏—è –Ω–µ —Å–æ–≤–ø–∞–¥–∞–µ—Ç

            # –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–ø—ã—Ç–∞
            experience_raw = vac.get("experience", {}).get("title", "").lower()
            if "–±–µ–∑ –æ–ø—ã—Ç–∞" in experience_raw:
                experience = "–ù–µ—Ç –æ–ø—ã—Ç–∞"
            elif "1 –≥–æ–¥" in experience_raw:
                experience = "–û—Ç 1 –≥–æ–¥–∞ –¥–æ 3 –ª–µ—Ç"
            elif "3 –ª–µ—Ç" in experience_raw:
                experience = "–û—Ç 3 –¥–æ 6 –ª–µ—Ç"
            elif "6 –ª–µ—Ç" in experience_raw:
                experience = "–ë–æ–ª–µ–µ 6 –ª–µ—Ç"
            else:
                experience = "–ù–µ —É–∫–∞–∑–∞–Ω–æ"

            # –ö–∞—Ç–µ–≥–æ—Ä–∏–∏
            # categories = [pos["title"] for cat in vac.get("catalogues", []) for pos in cat.get("positions", [])]

            categories = vac.get('catalogues')[0]['positions'][0]['key']
            city = vac.get("town", {}).get("title", "–ù–µ —É–∫–∞–∑–∞–Ω–æ")
            classify = vac.get('catalogues')[0]['positions'][0]['title']

            if (categories in target_keys) and  (city in priority_cities):

              vacancy_data = {
                  "title": vac.get("profession", "–ù–µ —É–∫–∞–∑–∞–Ω–æ"),
                  "company": vac.get("firm_name", "–ù–µ —É–∫–∞–∑–∞–Ω–æ"),
                  "date": pub_date.strftime('%Y-%m-%d %H:%M:%S'),
                  "location": city,
                  "source": "superJob",
                  "employment": vac.get("type_of_work", {}).get("title", "–ù–µ —É–∫–∞–∑–∞–Ω–æ"),
                  "salary": f"{vac.get('payment_from', 0)} - {vac.get('payment_to', 0)} {vac.get('currency', '').upper()}",
                  "skills": vac.get("candidat", ""),
                  "link": vac.get("link"),
                  "new_category": classify_vacancy(classify, vac.get("profession", "–ù–µ —É–∫–∞–∑–∞–Ω–æ")),
                  "vacancy_type": classify,
                  "experience": experience
              }

              a_list.append(vacancy_data)

        time.sleep(1)

    return a_list


def habr_parsing():
    a_list = []
    num_list = 25

    for j in range(num_list):
        j+=1
        data = requests.get(f'https://career.habr.com/vacancies?page={j}&type=all')
        soup = BeautifulSoup(data.content, 'html.parser')
        vacancy = soup.find_all('div', class_='vacancy-card')
        for i in vacancy:
            time_vac = safe_find_text(i, 'time', class_='basic-date')
            time_vac = parse_russian_date(time_vac)
            if datetime.now() - time_vac < timedelta(days=1):
                experience = get_vacancy_level(i)
                if experience is None:
                    experience = '–ù–µ —É–∫–∞–∑–∞–Ω–æ'
                elif (experience == '–°—Ç–∞—Ä—à–∏–π (Senior)') or (experience == '–í–µ–¥—É—â–∏–π (Lead)') :
                    experience = "–û—Ç 3 –¥–æ 6 –ª–µ—Ç"
                elif experience == '–°—Ç–∞–∂—ë—Ä (Intern)':
                    experience = "–ù–µ—Ç –æ–ø—ã—Ç–∞"
                elif (experience == '–°—Ä–µ–¥–Ω–∏–π (Middle)') or (experience == '–ú–ª–∞–¥—à–∏–π (Junior)'):
                    experience = "–û—Ç 1 –≥–æ–¥–∞ –¥–æ 3 –ª–µ—Ç"
                
                location = safe_find_text(i, 'a', href=lambda x: x and 'city_id=' in x)

                if location is None:
                    location = '–£–¥–∞–ª–µ–Ω–Ω–∞—è —Ä–∞–±–æ—Ç–∞'
                vacancy_list = {
                "title": safe_find_text(i, 'a', class_='vacancy-card__title-link'),
                "company": safe_find_text(i, 'a', class_='link-comp', href=lambda x: x and '/companies/' in x),
                "date": datetime.now(),
                "location": location,
                'source' : 'habr',
                "employment": safe_find_text(i, 'span', class_='preserve-line', string=lambda x: x and '–ü–æ–ª–Ω—ã–π —Ä–∞–±–æ—á–∏–π –¥–µ–Ω—å' in x),
                "salary": safe_find_text(i, 'div', class_='basic-salary'),
                "skills": ', '.join([skill.text for skill in i.find_all('a', class_='link-comp', href=lambda x: x and '/skills/' in x)]) if i.find_all('a', class_='link-comp', href=lambda x: x and '/skills/' in x) else '',
                "link": "https://career.habr.com" + i.find('a', class_='vacancy-card__title-link')['href'] 
                    if i.find('a', class_='vacancy-card__title-link') else None,
                "new_category" : classify_vacancy(get_vacancy_categories(i), safe_find_text(i, 'a', class_='vacancy-card__title-link')),
                "vacancy_type": get_vacancy_categories(i),  # –î–æ–±–∞–≤–ª–µ–Ω–Ω—ã–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –∏–∑ /vacancies/spec/
                "experience": experience
                }

                a_list.append(vacancy_list)
            else:
                break
        time.sleep(1)
    return a_list

def parse_date(date_str):
    """–ü–∞—Ä—Å–∏—Ç –¥–∞—Ç—É –∏–∑ —Å—Ç—Ä–æ–∫–∏ –≤ —Ñ–æ—Ä–º–∞—Ç–µ '2025-06-25T13:02:24+0300'"""
    try:
    # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—É—é –∑–æ–Ω—É (+0300) –¥–ª—è —É–ø—Ä–æ—â–µ–Ω–∏—è (–º–æ–∂–Ω–æ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –æ—Ç–¥–µ–ª—å–Ω–æ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ)
        if isinstance(date_str, str) and 'T' in date_str:
            return datetime.strptime(date_str.split('+')[0], '%Y-%m-%dT%H:%M:%S')
        return date_str
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –¥–∞—Ç—ã {date_str}: {e}")
    return None # –∏–ª–∏ datetime.now() –¥–ª—è –ø–æ–¥—Å—Ç–∞–Ω–æ–≤–∫–∏ —Ç–µ–∫—É—â–µ–π –¥–∞—Ç—ã

def parse_russian_date(date_str):
    month_map = {
        '—è–Ω–≤–∞—Ä—è': 1, '—Ñ–µ–≤—Ä–∞–ª—è': 2, '–º–∞—Ä—Ç–∞': 3,
        '–∞–ø—Ä–µ–ª—è': 4, '–º–∞—è': 5, '–∏—é–Ω—è': 6,
        '–∏—é–ª—è': 7, '–∞–≤–≥—É—Å—Ç–∞': 8, '—Å–µ–Ω—Ç—è–±—Ä—è': 9,
        '–æ–∫—Ç—è–±—Ä—è': 10, '–Ω–æ—è–±—Ä—è': 11, '–¥–µ–∫–∞–±—Ä—è': 12
    }
    
    # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–µ–Ω—å –∏ –º–µ—Å—è—Ü
    match = re.match(r'(\d{1,2})\s+([–∞-—è]+)', date_str.lower())
    if not match:
        return None
    
    day = int(match.group(1))
    month_ru = match.group(2)
    month = month_map.get(month_ru)
    
    if not month:
        return None
    
    # –ë–µ—Ä–µ–º —Ç–µ–∫—É—â–∏–π –≥–æ–¥ (–º–æ–∂–Ω–æ –∑–∞–¥–∞—Ç—å —è–≤–Ω–æ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ)
    year = datetime.now().year
    
    return datetime(year=year, month=month, day=day)

def loading_to_base(hh_list, habr_list, superjob_list):
    conn = psycopg2.connect(
        host="pg4.sweb.ru",
        port=5433,
        database="maksimarkh",
        user="maksimarkh",
        password="Maksim1232145!"
    )
    cursor = conn.cursor()

    cursor.execute("SELECT distinct link FROM vacans")
    link_records = cursor.fetchall()
    link_list = [record[0] for record in link_records if record[0] is not None]

    cursor.execute("SELECT distinct link FROM vacans where date > CURRENT_DATE")
    link_records = cursor.fetchall()
    link_list_now = [record[0] for record in link_records if record[0] is not None]

    

    for i in habr_list:
        if i['link'] not in link_list_now:
            
            cursor.execute("""
                INSERT INTO vacans (title, company, date, employment, salary, skills, link, location, source, new_category, vacancy_type, experience) 
                VALUES (%s, %s, %s, %s, %s, %s, %s, %s,  %s,  %s, %s, %s)
            """, (
                i['title'], 
                i['company'], 
                i['date'], 
                i['employment'], 
                i['salary'], 
                i['skills'], 
                i['link'],
                i['location'],
                i['source'],
                i['new_category'],
                i['vacancy_type'],
                i['experience']
                
            ))

    for i in hh_list:
        if i['link'] not in link_list:
            date_value = parse_date(i['date'])

            cursor.execute("""
            INSERT INTO vacans (title, company, date, employment, salary, skills, link, location, source, vacancy_type, experience, new_category)
            VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
            """, (
            i['title'],
            i['company'],
            date_value,
            i['employment'],
            str(i['salary']),
            i['skills'],
            i['link'],
            i['location'],
            i['source'],
            i['vacancy_type'],
            i['experience'],
            i['new_category']

            ))

    for i in superjob_list:
        if i['link'] not in link_list:
            date_value = parse_date(i['date'])

            cursor.execute("""
            INSERT INTO vacans (title, company, date, employment, salary, skills, link, location, source, vacancy_type, experience, new_category)
            VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
            """, (
            i['title'],
            i['company'],
            date_value,
            i['employment'],
            str(i['salary']),
            i['skills'],
            i['link'],
            i['location'],
            i['source'],
            i['vacancy_type'],
            i['experience'],
            i['new_category']

            ))
    conn.commit()
    cursor.close()
    conn.close()


def main():
    try:
        logger.info("–ó–∞–ø—É—Å–∫ –ø–∞—Ä—Å–µ—Ä–∞...")
        hh_list = hh_parsing()
        logger.info("HH –∑–∞–≥—Ä—É–∑–∏–ª–æ...")
        habr_list = habr_parsing()
        logger.info("Habr –∑–∞–≥—Ä—É–∑–∏–ª–æ...")
        superjob_list = superjob_parsing()
        logger.info("Superjob –∑–∞–≥—Ä—É–∑–∏–ª–æ...")

    
        
        if hh_list or habr_list or superjob_list:
            logger.info("–ù–∞—á–∞–ª–æ –∑–∞–≥—Ä—É–∑–∫–∏ –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö")
            loading_to_base(hh_list, habr_list, superjob_list)
            
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞: {e}", exc_info=True)

if __name__ == "__main__":
    main()
